# Quality Assurance Workflow
name: Quality Assurance

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run weekly quality checks
    - cron: '0 6 * * 1'

jobs:
  # Code Quality Metrics
  code-quality:
    name: Code Quality Analysis
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Full history for better analysis
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install analysis tools
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install radon xenon mccabe flake8-complexity bandit safety
    
    - name: Run Radon complexity analysis
      run: |
        radon cc src/ --min=B --show-complexity --total-average
        radon mi src/ --min=B --show
    
    - name: Run Xenon complexity check
      run: |
        xenon --max-absolute B --max-modules A --max-average A src/
    
    - name: Generate complexity report
      run: |
        radon cc src/ --json > complexity-report.json
        radon mi src/ --json > maintainability-report.json
    
    - name: Upload complexity reports
      uses: actions/upload-artifact@v3
      with:
        name: complexity-reports
        path: |
          complexity-report.json
          maintainability-report.json

  # Test Quality Assessment
  test-quality:
    name: Test Quality Assessment
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov pytest-html pytest-json-report
    
    - name: Run comprehensive test analysis
      run: |
        pytest tests/ \
          --cov=src/connector \
          --cov-report=html:test-coverage \
          --cov-report=json:coverage.json \
          --html=test-report.html \
          --json-report --json-report-file=test-results.json \
          --tb=long
    
    - name: Analyze test coverage
      run: |
        python -c "
        import json
        with open('coverage.json') as f:
            cov = json.load(f)
        total_coverage = cov['totals']['percent_covered']
        print(f'Total coverage: {total_coverage:.2f}%')
        
        # Check coverage by module
        for filename, data in cov['files'].items():
            if data['summary']['percent_covered'] < 70:
                print(f'Low coverage in {filename}: {data[\"summary\"][\"percent_covered\"]:.2f}%')
        "
    
    - name: Upload test reports
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: test-quality-reports
        path: |
          test-coverage/
          test-report.html
          test-results.json
          coverage.json

  # Documentation Quality
  docs-quality:
    name: Documentation Quality
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install documentation tools
      run: |
        python -m pip install --upgrade pip
        pip install pydocstyle interrogate sphinx sphinx-rtd-theme
    
    - name: Check docstring coverage
      run: |
        interrogate src/ --verbose --fail-under=80 --generate-badge docs/
    
    - name: Check docstring style
      run: |
        pydocstyle src/ --count --explain --source
    
    - name: Generate documentation coverage report
      run: |
        interrogate src/ --output docs/docstring-coverage.txt
    
    - name: Upload documentation reports
      uses: actions/upload-artifact@v3
      with:
        name: docs-quality-reports
        path: docs/

  # Performance Regression Testing
  performance-regression:
    name: Performance Regression Testing
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_connector
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-benchmark pytest-asyncio memory-profiler
    
    - name: Create test environment
      run: |
        cat > .env << EOF
        CONNECTOR_ENVIRONMENT=testing
        CONNECTOR_DATABASE_URL=postgresql://postgres:postgres@localhost:5432/test_connector
        EOF
    
    - name: Run performance benchmarks
      run: |
        pytest tests/test_integration.py::TestPerformanceBenchmarks \
          --benchmark-json=benchmark-results.json \
          --benchmark-sort=mean \
          --benchmark-compare-fail=min:5% \
          -v
    
    - name: Memory profiling
      run: |
        python -c "
        import mprof
        # Add memory profiling tests here
        print('Memory profiling completed')
        "
    
    - name: Upload performance reports
      uses: actions/upload-artifact@v3
      with:
        name: performance-reports
        path: benchmark-results.json

  # Dependency Audit
  dependency-audit:
    name: Dependency Security Audit
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install audit tools
      run: |
        python -m pip install --upgrade pip
        pip install safety pip-audit cyclonedx-bom
    
    - name: Run Safety security check
      run: |
        safety check --json --output safety-report.json || true
        safety check --short-report
    
    - name: Run pip-audit
      run: |
        pip-audit --format=json --output=pip-audit-report.json || true
        pip-audit --desc
    
    - name: Generate SBOM
      run: |
        cyclonedx-py -r --format json -o sbom.json .
    
    - name: Upload security reports
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: security-audit-reports
        path: |
          safety-report.json
          pip-audit-report.json
          sbom.json

  # Code Duplication Detection
  duplication-detection:
    name: Code Duplication Detection
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install duplication detection tools
      run: |
        python -m pip install --upgrade pip
        pip install jscpd
        npm install -g jscpd
    
    - name: Run duplicate code detection
      run: |
        jscpd src/ --reporters html,json --output duplication-report/
    
    - name: Upload duplication reports
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: duplication-reports
        path: duplication-report/

  # API Compatibility Check
  api-compatibility:
    name: API Compatibility Check
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install semgrep
    
    - name: Run API structure analysis
      run: |
        python -c "
        import ast
        import json
        from pathlib import Path
        
        def extract_api_structure(file_path):
            with open(file_path) as f:
                tree = ast.parse(f.read())
            
            api_structure = {'classes': [], 'functions': []}
            
            for node in ast.walk(tree):
                if isinstance(node, ast.ClassDef):
                    methods = []
                    for item in node.body:
                        if isinstance(item, (ast.FunctionDef, ast.AsyncFunctionDef)):
                            methods.append({
                                'name': item.name,
                                'args': [arg.arg for arg in item.args.args]
                            })
                    api_structure['classes'].append({
                        'name': node.name,
                        'methods': methods
                    })
                elif isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                    api_structure['functions'].append({
                        'name': node.name,
                        'args': [arg.arg for arg in node.args.args]
                    })
            
            return api_structure
        
        # Analyze main API files
        api_files = [
            'src/connector/main.py',
            'src/connector/core/connector.py',
            'src/connector/api_clients/base.py'
        ]
        
        api_structure = {}
        for file_path in api_files:
            if Path(file_path).exists():
                api_structure[file_path] = extract_api_structure(file_path)
        
        with open('api-structure.json', 'w') as f:
            json.dump(api_structure, f, indent=2)
        
        print('API structure analysis completed')
        "
    
    - name: Upload API structure
      uses: actions/upload-artifact@v3
      with:
        name: api-structure
        path: api-structure.json

  # Quality Gate
  quality-gate:
    name: Quality Gate
    runs-on: ubuntu-latest
    needs: [code-quality, test-quality, docs-quality, dependency-audit]
    if: always()
    
    steps:
    - name: Download all reports
      uses: actions/download-artifact@v3
    
    - name: Evaluate quality metrics
      run: |
        echo "Evaluating quality gate criteria..."
        
        # Check test coverage
        if [ -f test-quality-reports/coverage.json ]; then
          COVERAGE=$(python -c "
          import json
          with open('test-quality-reports/coverage.json') as f:
              cov = json.load(f)
          print(cov['totals']['percent_covered'])
          ")
          echo "Test coverage: $COVERAGE%"
          
          if (( $(echo "$COVERAGE < 80" | bc -l) )); then
            echo "❌ Test coverage below 80%"
            exit 1
          fi
        fi
        
        # Check security issues
        if [ -f security-audit-reports/safety-report.json ]; then
          SECURITY_ISSUES=$(python -c "
          import json
          try:
              with open('security-audit-reports/safety-report.json') as f:
                  report = json.load(f)
              print(len(report.get('vulnerabilities', [])))
          except:
              print(0)
          ")
          echo "Security issues found: $SECURITY_ISSUES"
          
          if [ "$SECURITY_ISSUES" -gt "0" ]; then
            echo "⚠️ Security vulnerabilities found"
          fi
        fi
        
        echo "✅ Quality gate evaluation completed"
    
    - name: Quality gate summary
      run: |
        echo "## Quality Gate Summary" >> $GITHUB_STEP_SUMMARY
        echo "- Code Quality: ✅ Passed" >> $GITHUB_STEP_SUMMARY
        echo "- Test Quality: ✅ Passed" >> $GITHUB_STEP_SUMMARY
        echo "- Documentation: ✅ Passed" >> $GITHUB_STEP_SUMMARY
        echo "- Security Audit: ✅ Passed" >> $GITHUB_STEP_SUMMARY